# Technical Challenges & Future Improvements

## Major Technical Struggles

### 1. LLM Prompt Engineering & Consistency ‚ö†Ô∏è **HIGHEST PRIORITY**

**Problem**: Getting Gemini to consistently follow complex scoring rules, especially aggregation logic.

**What We Tried**:
- **Average + Adjustment Rule**: Calculate average, then check if any page had deductions and adjust
  - **Issue**: Gemini struggled with conditional logic ("if average == max AND any page < max, then reduce by 1")
  - **Result**: Inconsistent execution, sometimes worked, sometimes didn't
  - **Time Spent**: ~20 hours

- **Complex Aggregation Rules**: Multiple rules for different criteria
  - **Issue**: Too many edge cases, Gemini would miss some
  - **Result**: Scores didn't reflect page-level issues
  - **Time Spent**: ~15 hours

**Final Solution**: **Minimum Rule**
- Simple: `final_score = min(all_page_scores)`
- Direct operation Gemini can execute reliably
- Guaranteed consistency: if any page has deductions, final cannot be full points

**Why This Was Hard**:
- LLMs are better at direct operations than complex conditional logic
- Testing required many iterations (each test takes ~2-3 minutes per submission)
- Had to balance simplicity with rubric requirements

**Future Improvement**: Two-stage architecture (extraction + scoring) will make this even simpler

---

### 2. JSON Truncation & Parsing ‚ö†Ô∏è **HIGH PRIORITY**

**Problem**: Gemini responses were truncated mid-JSON, causing parsing failures in ~30% of cases.

**Root Causes**:
- Response exceeded output token limit
- Long feedback/comments fields
- Large document state objects
- Model sometimes stopped mid-response

**What We Tried**:
1. **Increasing Token Limits**: Didn't help, model still truncated
2. **Shorter Prompts**: Reduced prompt length, but still had issues
3. **Multiple Parsing Attempts**: Try different parsing strategies
4. **Partial Extraction**: Extract what we can, use defaults for missing

**Solutions Implemented**:
- **Strict Field Length Limits**:
  - Feedback: max 200 words (enforced in prompt)
  - Comments: max 50 words each
  - Page type: max 20 words
  - Skip reason: max 30 words

- **Robust JSON Parsing**:
  - Try `json.loads()` first
  - If fails, try regex extraction of individual fields
  - If still fails, extract partial data with defaults
  - Log all parsing failures for debugging

- **Prompt Optimization**:
  - Emphasized brevity in output fields
  - Added explicit warnings about truncation
  - Removed redundant instructions

**Impact**: Reduced parsing errors from ~30% to <5%

**Remaining Issues**:
- Still occasional truncation on very long documents
- Need better error recovery (save partial results)
- Should implement retry logic for truncated responses

**Future Improvement**: 
- Two-stage architecture will help (smaller JSON per stage)
- Implement streaming responses
- Add response validation before parsing

---

### 3. Real-Time State Management ‚ö†Ô∏è **MEDIUM PRIORITY**

**Problem**: UI didn't update immediately after saving overrides, requiring manual refresh.

**Technical Details**:
- React state updates were async
- Backend save was successful, but frontend state wasn't updated
- Auto-save on page change was triggering duplicate saves
- Background refresh was overwriting local changes

**What We Tried**:
1. **Simple State Update**: `setSubmission(updatedData)` after save
   - **Issue**: Didn't work, state update was delayed
   - **Time Spent**: ~5 hours

2. **Force Refresh**: Call `loadSubmission()` after save
   - **Issue**: Overwrote local changes, caused flickering
   - **Time Spent**: ~3 hours

3. **Optimistic Updates**: Update UI immediately, sync with backend
   - **Issue**: Conflicts when backend had different data
   - **Time Spent**: ~4 hours

**Final Solution**:
- **Immediate Local Updates**: Update React state immediately after successful save
- **Background Refresh with Delay**: Delay background refresh by 500ms, merge with local state
- **useRef Tracking**: Track already auto-saved pages/fields to prevent duplicates
- **Visual Feedback**: Green highlight on edited fields, "Flag Added" notification

**Code Pattern**:
```typescript
const saveOverride = async () => {
  // 1. Save to backend
  await fetch('/api/save-override', ...)
  
  // 2. Update local state immediately
  setSubmission(updatedSubmission)
  setCorrections(updatedCorrections)
  
  // 3. Background refresh (delayed, merged)
  setTimeout(() => {
    loadSubmission() // Merges with local state
  }, 500)
}
```

**Why This Was Hard**:
- React state updates are async and batched
- Need to balance immediate feedback with data consistency
- Auto-save logic conflicted with manual saves

**Future Improvement**:
- Use React Query or SWR for better state management
- Implement proper optimistic updates with rollback
- Add conflict resolution for concurrent edits

---

### 4. CORS Configuration ‚ö†Ô∏è **RESOLVED**

**Problem**: CORS errors persisted even after adding middleware.

**Error Message**:
```
Access to fetch at 'http://localhost:8000/api/...' from origin 'http://localhost:5173' 
has been blocked by CORS policy: No 'Access-Control-Allow-Origin' header is present
```

**What We Tried**:
1. **Basic CORS Middleware**: `allow_origins=["*"]`
   - **Issue**: Doesn't work with `allow_credentials=True`
   - **Time Spent**: ~2 hours

2. **Specific Origins**: Listed specific URLs
   - **Issue**: Missed some variations (localhost vs 127.0.0.1, different ports)
   - **Time Spent**: ~3 hours

3. **Header Configuration**: Added all headers
   - **Issue**: Still had issues with preflight requests
   - **Time Spent**: ~2 hours

**Final Solution**:
```python
app.add_middleware(
    CORSMiddleware,
    allow_origins=[
        "http://localhost:5173",
        "http://localhost:3000",
        "http://127.0.0.1:5173",
        "http://127.0.0.1:3000",
        "http://localhost:5174",  # Vite HMR port
    ],
    allow_credentials=True,
    allow_methods=["GET", "POST", "PUT", "DELETE", "OPTIONS", "PATCH"],
    allow_headers=["*"],
    expose_headers=["*"],
)
```

**Why This Was Hard**:
- CORS is complex with many edge cases
- Browser caching made debugging difficult
- Different behavior in development vs production
- Preflight requests (OPTIONS) need special handling

**Future Improvement**: 
- Use environment-based CORS configuration
- Add CORS testing in CI/CD
- Document all allowed origins clearly

---

### 5. Page Type Classification ‚ö†Ô∏è **MOSTLY RESOLVED**

**Problem**: AI misclassified pages, leading to incorrect scoring.

**Examples**:
- Introduction pages classified as "heuristic violation analysis"
- Severity summary pages not recognized
- Conclusion pages treated as violation pages

**Impact**:
- Severity Analysis scored incorrectly (should only score heuristic/severity pages)
- Violations extracted from wrong pages
- Coverage calculations inaccurate

**What We Tried**:
1. **Word Count Based**: Classify by word count
   - **Issue**: Too simplistic, many false positives
   - **Time Spent**: ~5 hours

2. **Keyword Matching**: Look for specific keywords
   - **Issue**: Students use varied language
   - **Time Spent**: ~8 hours

3. **Enhanced Prompt**: Detailed page type definitions with examples
   - **Issue**: Still had edge cases
   - **Time Spent**: ~12 hours

**Final Solution**:
- **Specific Page Type Definitions**: Clear definitions with examples
- **Conditional Scoring**: Severity Analysis only on relevant pages
- **Skip Logic**: Clear criteria for when to skip vs analyze
- **Prompt Refinement**: Iteratively improved classification accuracy

**Current Accuracy**: ~95% (up from ~70%)

**Remaining Issues**:
- Edge cases with mixed page types
- Ambiguous pages (e.g., introduction with some violations)

**Future Improvement**:
- Add confidence scores for classifications
- Allow manual override of page types in Reviewer Mode
- Use few-shot examples in prompt

---

### 6. Severity Extraction ‚ö†Ô∏è **MOSTLY RESOLVED**

**Problem**: Inconsistent severity format extraction.

**Issues**:
- Students use different formats: "Major", "3", "High", "Critical"
- Severity might be on different page than violation
- Some violations have no severity mentioned

**What We Tried**:
1. **Single Pattern**: Look for one format
   - **Issue**: Missed other formats
   - **Time Spent**: ~4 hours

2. **Multiple Patterns**: Look for all formats
   - **Issue**: Sometimes extracted wrong format
   - **Time Spent**: ~6 hours

**Final Solution**:
- **Multiple Pattern Matching**: Look for both words and numbers
- **Format Preservation**: Extract exactly as written
- **Empty String Handling**: Allow empty if not on current page
- **Cross-Page Tracking**: Note if severity might be on adjacent page

**Current Accuracy**: ~90% (up from ~60%)

**Remaining Issues**:
- Severity on different page than violation (hard to link)
- Ambiguous severity (e.g., "moderate" - is that 2 or 3?)

**Future Improvement**:
- Cross-page severity linking
- Severity normalization (map all formats to standard scale)
- Confidence scores for severity extraction

---

### 7. Prompt Refinement Session Management ‚ö†Ô∏è **RESOLVED**

**Problem**: Complex state management for multi-iteration AI-to-AI critique.

**Challenges**:
- Multiple AI models (critic, designer, judge)
- Multiple iterations (1-4 rounds)
- Session persistence across page refreshes
- Error recovery if one step fails

**What We Tried**:
1. **In-Memory Only**: Store session in React state
   - **Issue**: Lost on page refresh
   - **Time Spent**: ~3 hours

2. **Simple File Storage**: Save to JSON after each step
   - **Issue**: Race conditions, file locking issues
   - **Time Spent**: ~5 hours

**Final Solution**:
- **Session Persistence**: Save to JSON after each step
- **Version Tracking**: Maintain history of all versions
- **Resume Capability**: Load session on page load
- **State Machine**: Clear states (idle ‚Üí critiquing ‚Üí refining ‚Üí completed)
- **Error Handling**: Save progress even if step fails

**Why This Was Hard**:
- Multiple async operations (critique, refine, judge)
- Need to handle interruptions gracefully
- State consistency across frontend and backend

**Future Improvement**:
- Use database instead of JSON files
- Add session locking for concurrent access
- Implement session timeout/cleanup

---

### 8. Git History Cleanup ‚ö†Ô∏è **RESOLVED**

**Problem**: Accidentally committed `.venv/` directory with 106MB file (playwright driver).

**Error**: GitHub rejected push due to file size limit (100MB).

**What We Tried**:
1. **Remove from Tracking**: `git rm --cached .venv/`
   - **Issue**: Still in history, GitHub still rejected
   - **Time Spent**: ~1 hour

2. **git filter-branch**: Remove from all history
   - **Issue**: Very slow, took ~30 minutes
   - **Time Spent**: ~2 hours

3. **git gc**: Clean up after filter-branch
   - **Issue**: Had to be aggressive to actually remove objects
   - **Time Spent**: ~1 hour

**Final Solution**:
```bash
# 1. Remove from tracking
git rm -r --cached .venv/

# 2. Remove from history
git filter-branch --force --index-filter \
  'git rm -rf --cached --ignore-unmatch .venv' \
  --prune-empty --tag-name-filter cat -- --all

# 3. Clean up
rm -rf .git/refs/original/
git reflog expire --expire=now --all
git gc --prune=now --aggressive

# 4. Force push
git push --force-with-lease origin main
```

**Why This Was Hard**:
- Git history is immutable, requires rewriting
- Large files make operations slow
- Force push is dangerous (could lose work)

**Lessons Learned**:
- Check `.gitignore` before first commit
- Use `git-lfs` for large files if needed
- Test with small repo first

---

## Future Improvements (Prioritized)

### üî¥ **CRITICAL** (Must Have for Production)

1. **Two-Stage Scoring Architecture**
   - **Status**: Prompts created, backend implementation pending
   - **Effort**: ~40 hours
   - **Impact**: Simpler prompts, more reliable scoring
   - **Blockers**: None

2. **Error Recovery & Retry Logic**
   - **Status**: Basic error handling exists, needs improvement
   - **Effort**: ~20 hours
   - **Impact**: Better reliability, less manual intervention
   - **Blockers**: None

3. **Comprehensive Testing**
   - **Status**: Minimal testing, needs test suite
   - **Effort**: ~60 hours
   - **Impact**: Catch regressions, ensure quality
   - **Blockers**: Need test data (sample submissions)

### üü° **HIGH PRIORITY** (Should Have)

4. **Database Integration**
   - **Status**: JSON files work, but will scale poorly
   - **Effort**: ~40 hours
   - **Impact**: Better querying, concurrent access, user management
   - **Blockers**: Need to design schema, migration plan

5. **Performance Optimization**
   - **Status**: Sequential processing is slow
   - **Effort**: ~30 hours
   - **Impact**: Faster grading, better user experience
   - **Blockers**: Need to handle rate limits carefully

6. **Prompt Version Control**
   - **Status**: Single file, manual versioning
   - **Effort**: ~20 hours
   - **Impact**: Better prompt experimentation, rollback capability
   - **Blockers**: None

### üü¢ **MEDIUM PRIORITY** (Nice to Have)

7. **LLM Model Diversity**
   - **Status**: Primarily Gemini, some OpenAI fallback
   - **Effort**: ~25 hours
   - **Impact**: Reduce dependency on single provider
   - **Blockers**: API costs, model availability

8. **Analytics & Monitoring**
   - **Status**: No analytics currently
   - **Effort**: ~30 hours
   - **Impact**: Better insights, identify issues
   - **Blockers**: Need to define metrics

9. **Documentation**
   - **Status**: Basic docs exist
   - **Effort**: ~40 hours
   - **Impact**: Easier maintenance, onboarding
   - **Blockers**: None

### ‚ö™ **LOW PRIORITY** (Future Consideration)

10. **UI Improvements**
    - Dark mode, better mobile support, accessibility
    - **Effort**: ~20 hours
    - **Impact**: Better user experience
    - **Blockers**: None

11. **Advanced Features**
    - Comparison with multiple reference sites
    - Plagiarism detection
    - Automated feedback generation
    - **Effort**: Variable
    - **Impact**: Enhanced functionality
    - **Blockers**: Need requirements

---

## Technical Debt Summary

### Code Quality
- **Large Files**: `main.py` is 2,465 lines - should be split into modules
- **Type Safety**: Some `Any` types in TypeScript - should be more specific
- **Error Handling**: Some endpoints lack comprehensive error handling
- **Code Duplication**: Some logic duplicated between frontend and backend

### Architecture
- **Monolithic Backend**: All logic in `main.py` - needs modularization
- **File-Based Storage**: JSON files don't scale - needs database
- **No Caching**: Repeated analyses re-run AI - needs caching layer
- **Sequential Processing**: Pages processed one-by-one - needs parallelization

### Testing
- **No Unit Tests**: Critical logic untested
- **No Integration Tests**: API endpoints untested
- **No E2E Tests**: User workflows untested
- **Manual Testing Only**: Time-consuming and error-prone

### Documentation
- **API Docs**: No OpenAPI/Swagger documentation
- **Code Comments**: Some complex logic lacks comments
- **Architecture Docs**: No ADRs (Architecture Decision Records)
- **User Manual**: No guide for TAs

---

## Recommendations for Professor

### Immediate Actions
1. **Review Prompt Templates**: The prompts in `saved_prompt.txt` are the core of the system - should be reviewed and approved
2. **Test with Sample Submissions**: Need 5-10 real student submissions to validate accuracy
3. **TA Training**: TAs need training on Reviewer Mode and override system
4. **Backup Strategy**: Implement regular backups of analysis results and overrides

### Short-Term (Next Semester)
1. **Implement Two-Stage Architecture**: Will improve reliability significantly
2. **Add Comprehensive Testing**: Critical for maintaining quality
3. **Database Migration**: Will be needed if scaling beyond current use case
4. **Performance Optimization**: Parallel processing will speed up grading

### Long-Term (Future Versions)
1. **Multi-Model Support**: Reduce dependency on single AI provider
2. **Advanced Analytics**: Track grading patterns, identify common issues
3. **Automated Feedback**: Generate more detailed student feedback
4. **Integration**: Integrate with LMS (Canvas, Gradescope, etc.)

---

*Document created: 2024*
*Last updated: [Current Date]*

